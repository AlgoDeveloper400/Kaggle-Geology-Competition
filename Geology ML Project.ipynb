{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdda2998-d743-419f-9d8c-9992499cc197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geology_id</th>\n",
       "      <th>-299</th>\n",
       "      <th>-298</th>\n",
       "      <th>-297</th>\n",
       "      <th>-296</th>\n",
       "      <th>-295</th>\n",
       "      <th>-294</th>\n",
       "      <th>-293</th>\n",
       "      <th>-292</th>\n",
       "      <th>-291</th>\n",
       "      <th>...</th>\n",
       "      <th>r_9_pos_291</th>\n",
       "      <th>r_9_pos_292</th>\n",
       "      <th>r_9_pos_293</th>\n",
       "      <th>r_9_pos_294</th>\n",
       "      <th>r_9_pos_295</th>\n",
       "      <th>r_9_pos_296</th>\n",
       "      <th>r_9_pos_297</th>\n",
       "      <th>r_9_pos_298</th>\n",
       "      <th>r_9_pos_299</th>\n",
       "      <th>r_9_pos_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g_08504df78e</td>\n",
       "      <td>-9.253171</td>\n",
       "      <td>-9.224713</td>\n",
       "      <td>-9.196256</td>\n",
       "      <td>-9.167798</td>\n",
       "      <td>-9.13934</td>\n",
       "      <td>-9.110882</td>\n",
       "      <td>-9.082424</td>\n",
       "      <td>-9.053967</td>\n",
       "      <td>-9.025509</td>\n",
       "      <td>...</td>\n",
       "      <td>16.943604</td>\n",
       "      <td>17.002798</td>\n",
       "      <td>17.061992</td>\n",
       "      <td>17.121186</td>\n",
       "      <td>17.180380</td>\n",
       "      <td>17.239573</td>\n",
       "      <td>17.298767</td>\n",
       "      <td>17.357961</td>\n",
       "      <td>17.417155</td>\n",
       "      <td>17.476349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g_ea47af5886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.608719</td>\n",
       "      <td>3.646996</td>\n",
       "      <td>3.685274</td>\n",
       "      <td>3.723551</td>\n",
       "      <td>3.761828</td>\n",
       "      <td>3.800105</td>\n",
       "      <td>3.838382</td>\n",
       "      <td>3.876659</td>\n",
       "      <td>3.914937</td>\n",
       "      <td>3.953214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g_29c088d23e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.774845</td>\n",
       "      <td>12.813151</td>\n",
       "      <td>12.851456</td>\n",
       "      <td>12.889762</td>\n",
       "      <td>12.928067</td>\n",
       "      <td>12.966373</td>\n",
       "      <td>13.004678</td>\n",
       "      <td>13.042984</td>\n",
       "      <td>13.081289</td>\n",
       "      <td>13.119595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g_5f895697a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.120419</td>\n",
       "      <td>12.159944</td>\n",
       "      <td>12.199469</td>\n",
       "      <td>12.238994</td>\n",
       "      <td>12.278520</td>\n",
       "      <td>12.318045</td>\n",
       "      <td>12.357570</td>\n",
       "      <td>12.397095</td>\n",
       "      <td>12.436620</td>\n",
       "      <td>12.476145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g_20617e2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.146060</td>\n",
       "      <td>-2.153430</td>\n",
       "      <td>-2.160799</td>\n",
       "      <td>-2.168168</td>\n",
       "      <td>-2.175537</td>\n",
       "      <td>-2.182906</td>\n",
       "      <td>-2.190275</td>\n",
       "      <td>-2.197645</td>\n",
       "      <td>-2.205014</td>\n",
       "      <td>-2.208960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     geology_id      -299      -298      -297      -296     -295      -294  \\\n",
       "0  g_08504df78e -9.253171 -9.224713 -9.196256 -9.167798 -9.13934 -9.110882   \n",
       "1  g_ea47af5886       NaN       NaN       NaN       NaN      NaN       NaN   \n",
       "2  g_29c088d23e       NaN       NaN       NaN       NaN      NaN       NaN   \n",
       "3  g_5f895697a1       NaN       NaN       NaN       NaN      NaN       NaN   \n",
       "4  g_20617e2013       NaN       NaN       NaN       NaN      NaN       NaN   \n",
       "\n",
       "       -293      -292      -291  ...  r_9_pos_291  r_9_pos_292  r_9_pos_293  \\\n",
       "0 -9.082424 -9.053967 -9.025509  ...    16.943604    17.002798    17.061992   \n",
       "1       NaN       NaN       NaN  ...     3.608719     3.646996     3.685274   \n",
       "2       NaN       NaN       NaN  ...    12.774845    12.813151    12.851456   \n",
       "3       NaN       NaN       NaN  ...    12.120419    12.159944    12.199469   \n",
       "4       NaN       NaN       NaN  ...    -2.146060    -2.153430    -2.160799   \n",
       "\n",
       "   r_9_pos_294  r_9_pos_295  r_9_pos_296  r_9_pos_297  r_9_pos_298  \\\n",
       "0    17.121186    17.180380    17.239573    17.298767    17.357961   \n",
       "1     3.723551     3.761828     3.800105     3.838382     3.876659   \n",
       "2    12.889762    12.928067    12.966373    13.004678    13.042984   \n",
       "3    12.238994    12.278520    12.318045    12.357570    12.397095   \n",
       "4    -2.168168    -2.175537    -2.182906    -2.190275    -2.197645   \n",
       "\n",
       "   r_9_pos_299  r_9_pos_300  \n",
       "0    17.417155    17.476349  \n",
       "1     3.914937     3.953214  \n",
       "2    13.081289    13.119595  \n",
       "3    12.436620    12.476145  \n",
       "4    -2.205014    -2.208960  \n",
       "\n",
       "[5 rows x 3301 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\ML Database\\Geology Datasets\\data\\train.csv\")\n",
    "\n",
    "# Display the first 5 rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "610bcb69-8cb1-4424-9655-de38285e0198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geology_id</th>\n",
       "      <th>-299</th>\n",
       "      <th>-298</th>\n",
       "      <th>-297</th>\n",
       "      <th>-296</th>\n",
       "      <th>-295</th>\n",
       "      <th>-294</th>\n",
       "      <th>-293</th>\n",
       "      <th>-292</th>\n",
       "      <th>-291</th>\n",
       "      <th>...</th>\n",
       "      <th>r_9_pos_291</th>\n",
       "      <th>r_9_pos_292</th>\n",
       "      <th>r_9_pos_293</th>\n",
       "      <th>r_9_pos_294</th>\n",
       "      <th>r_9_pos_295</th>\n",
       "      <th>r_9_pos_296</th>\n",
       "      <th>r_9_pos_297</th>\n",
       "      <th>r_9_pos_298</th>\n",
       "      <th>r_9_pos_299</th>\n",
       "      <th>r_9_pos_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g_08504df78e</td>\n",
       "      <td>-9.253171</td>\n",
       "      <td>-9.224713</td>\n",
       "      <td>-9.196256</td>\n",
       "      <td>-9.167798</td>\n",
       "      <td>-9.139340</td>\n",
       "      <td>-9.110882</td>\n",
       "      <td>-9.082424</td>\n",
       "      <td>-9.053967</td>\n",
       "      <td>-9.025509</td>\n",
       "      <td>...</td>\n",
       "      <td>16.943604</td>\n",
       "      <td>17.002798</td>\n",
       "      <td>17.061992</td>\n",
       "      <td>17.121186</td>\n",
       "      <td>17.180380</td>\n",
       "      <td>17.239573</td>\n",
       "      <td>17.298767</td>\n",
       "      <td>17.357961</td>\n",
       "      <td>17.417155</td>\n",
       "      <td>17.476349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g_ea47af5886</td>\n",
       "      <td>3.653826</td>\n",
       "      <td>3.653826</td>\n",
       "      <td>3.653826</td>\n",
       "      <td>3.653826</td>\n",
       "      <td>3.653826</td>\n",
       "      <td>3.653826</td>\n",
       "      <td>3.653826</td>\n",
       "      <td>3.653826</td>\n",
       "      <td>3.653826</td>\n",
       "      <td>...</td>\n",
       "      <td>3.608719</td>\n",
       "      <td>3.646996</td>\n",
       "      <td>3.685274</td>\n",
       "      <td>3.723551</td>\n",
       "      <td>3.761828</td>\n",
       "      <td>3.800105</td>\n",
       "      <td>3.838382</td>\n",
       "      <td>3.876659</td>\n",
       "      <td>3.914937</td>\n",
       "      <td>3.953214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g_29c088d23e</td>\n",
       "      <td>-1.224028</td>\n",
       "      <td>-1.224028</td>\n",
       "      <td>-1.224028</td>\n",
       "      <td>-1.224028</td>\n",
       "      <td>-1.224028</td>\n",
       "      <td>-1.224028</td>\n",
       "      <td>-1.224028</td>\n",
       "      <td>-1.224028</td>\n",
       "      <td>-1.224028</td>\n",
       "      <td>...</td>\n",
       "      <td>12.774845</td>\n",
       "      <td>12.813151</td>\n",
       "      <td>12.851456</td>\n",
       "      <td>12.889762</td>\n",
       "      <td>12.928067</td>\n",
       "      <td>12.966373</td>\n",
       "      <td>13.004678</td>\n",
       "      <td>13.042984</td>\n",
       "      <td>13.081289</td>\n",
       "      <td>13.119595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g_5f895697a1</td>\n",
       "      <td>-4.022961</td>\n",
       "      <td>-4.022961</td>\n",
       "      <td>-4.022961</td>\n",
       "      <td>-4.022961</td>\n",
       "      <td>-4.022961</td>\n",
       "      <td>-4.022961</td>\n",
       "      <td>-4.022961</td>\n",
       "      <td>-4.022961</td>\n",
       "      <td>-4.022961</td>\n",
       "      <td>...</td>\n",
       "      <td>12.120419</td>\n",
       "      <td>12.159944</td>\n",
       "      <td>12.199469</td>\n",
       "      <td>12.238994</td>\n",
       "      <td>12.278520</td>\n",
       "      <td>12.318045</td>\n",
       "      <td>12.357570</td>\n",
       "      <td>12.397095</td>\n",
       "      <td>12.436620</td>\n",
       "      <td>12.476145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g_20617e2013</td>\n",
       "      <td>0.797643</td>\n",
       "      <td>0.797643</td>\n",
       "      <td>0.797643</td>\n",
       "      <td>0.797643</td>\n",
       "      <td>0.797643</td>\n",
       "      <td>0.797643</td>\n",
       "      <td>0.797643</td>\n",
       "      <td>0.797643</td>\n",
       "      <td>0.797643</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.146060</td>\n",
       "      <td>-2.153430</td>\n",
       "      <td>-2.160799</td>\n",
       "      <td>-2.168168</td>\n",
       "      <td>-2.175537</td>\n",
       "      <td>-2.182906</td>\n",
       "      <td>-2.190275</td>\n",
       "      <td>-2.197645</td>\n",
       "      <td>-2.205014</td>\n",
       "      <td>-2.208960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     geology_id      -299      -298      -297      -296      -295      -294  \\\n",
       "0  g_08504df78e -9.253171 -9.224713 -9.196256 -9.167798 -9.139340 -9.110882   \n",
       "1  g_ea47af5886  3.653826  3.653826  3.653826  3.653826  3.653826  3.653826   \n",
       "2  g_29c088d23e -1.224028 -1.224028 -1.224028 -1.224028 -1.224028 -1.224028   \n",
       "3  g_5f895697a1 -4.022961 -4.022961 -4.022961 -4.022961 -4.022961 -4.022961   \n",
       "4  g_20617e2013  0.797643  0.797643  0.797643  0.797643  0.797643  0.797643   \n",
       "\n",
       "       -293      -292      -291  ...  r_9_pos_291  r_9_pos_292  r_9_pos_293  \\\n",
       "0 -9.082424 -9.053967 -9.025509  ...    16.943604    17.002798    17.061992   \n",
       "1  3.653826  3.653826  3.653826  ...     3.608719     3.646996     3.685274   \n",
       "2 -1.224028 -1.224028 -1.224028  ...    12.774845    12.813151    12.851456   \n",
       "3 -4.022961 -4.022961 -4.022961  ...    12.120419    12.159944    12.199469   \n",
       "4  0.797643  0.797643  0.797643  ...    -2.146060    -2.153430    -2.160799   \n",
       "\n",
       "   r_9_pos_294  r_9_pos_295  r_9_pos_296  r_9_pos_297  r_9_pos_298  \\\n",
       "0    17.121186    17.180380    17.239573    17.298767    17.357961   \n",
       "1     3.723551     3.761828     3.800105     3.838382     3.876659   \n",
       "2    12.889762    12.928067    12.966373    13.004678    13.042984   \n",
       "3    12.238994    12.278520    12.318045    12.357570    12.397095   \n",
       "4    -2.168168    -2.175537    -2.182906    -2.190275    -2.197645   \n",
       "\n",
       "   r_9_pos_299  r_9_pos_300  \n",
       "0    17.417155    17.476349  \n",
       "1     3.914937     3.953214  \n",
       "2    13.081289    13.119595  \n",
       "3    12.436620    12.476145  \n",
       "4    -2.205014    -2.208960  \n",
       "\n",
       "[5 rows x 3301 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\ML Database\\Geology Datasets\\data\\train.csv\")\n",
    "\n",
    "# Exclude 'geology_id' from interpolation\n",
    "columns_to_interpolate = df.columns[df.columns != 'geology_id']\n",
    "\n",
    "# Apply linear interpolation across columns (axis=1)\n",
    "df[columns_to_interpolate] = df[columns_to_interpolate].interpolate(\n",
    "    method='linear', axis=1, limit_direction='both'\n",
    ")\n",
    "\n",
    "# If any NaNs still remain (e.g., all values were NaN in a row), fallback to column mean\n",
    "df[columns_to_interpolate] = df[columns_to_interpolate].fillna(df[columns_to_interpolate].mean())\n",
    "\n",
    "# Define path to save the new CSV\n",
    "save_folder = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder, \"filled_train.csv\")\n",
    "\n",
    "# Save the filled DataFrame\n",
    "df.to_csv(save_path, index=False)\n",
    "\n",
    "# Optionally print the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478cfe85-55b9-4ad1-869f-12475d288ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input columns: 300\n",
      "Number of target columns: 3000\n",
      "Saved target columns list to: C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\target_cols.pkl\n",
      "Epoch 1/50 - Loss: 21.670430\n",
      "Epoch 2/50 - Loss: 12.150416\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pickle\n",
    "#ORGINAL ACCURACY OF 66!\n",
    "# === Load training data ===\n",
    "train_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\filled_train.csv\"\n",
    "df = pd.read_csv(train_path)\n",
    "\n",
    "# === Extract only columns named '-299' to '0' ===\n",
    "input_cols = [str(i) for i in range(-299, 1) if str(i) in df.columns]\n",
    "\n",
    "# Targets are all columns except 'geology_id' and inputs\n",
    "target_cols = [col for col in df.columns if col not in input_cols + ['geology_id']]\n",
    "\n",
    "print(f\"Number of input columns: {len(input_cols)}\")\n",
    "print(f\"Number of target columns: {len(target_cols)}\")\n",
    "\n",
    "# Save target_cols list for inference use\n",
    "target_cols_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\target_cols.pkl\"\n",
    "with open(target_cols_path, \"wb\") as f:\n",
    "    pickle.dump(target_cols, f)\n",
    "print(f\"Saved target columns list to: {target_cols_path}\")\n",
    "\n",
    "# Prepare training data arrays\n",
    "X_train = df[input_cols].values.astype(np.float32)\n",
    "Y_train = df[target_cols].values.astype(np.float32)\n",
    "\n",
    "# === Define Autoencoder ===\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=1024, bottleneck_dim=300, output_dim=None):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        output_dim = output_dim or input_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, bottleneck_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(bottleneck_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# === Train model ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Autoencoder(input_dim=X_train.shape[1], output_dim=Y_train.shape[1]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train).float(), torch.tensor(Y_train).float())\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "epochs = 50\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss / len(train_loader):.6f}\")\n",
    "\n",
    "# === Save the model ===\n",
    "save_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\autoencoder_model.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d5a3a9-899c-46e5-8d60-e3e40a86ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input columns: 300\n",
      "Number of target columns: 3000\n",
      "Saved target columns list to: C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\target_cols.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nokul\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 - Loss: 0.100434\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# === Load training data ===\n",
    "train_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\filled_train.csv\"\n",
    "df = pd.read_csv(train_path)\n",
    "\n",
    "# === Extract only columns named '-299' to '0' ===\n",
    "input_cols = [str(i) for i in range(-299, 1) if str(i) in df.columns]\n",
    "\n",
    "# Targets are all columns except 'geology_id' and inputs\n",
    "target_cols = [col for col in df.columns if col not in input_cols + ['geology_id']]\n",
    "\n",
    "print(f\"Number of input columns: {len(input_cols)}\")\n",
    "print(f\"Number of target columns: {len(target_cols)}\")\n",
    "\n",
    "# Save target_cols list for inference use\n",
    "target_cols_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\target_cols.pkl\"\n",
    "with open(target_cols_path, \"wb\") as f:\n",
    "    pickle.dump(target_cols, f)\n",
    "print(f\"Saved target columns list to: {target_cols_path}\")\n",
    "\n",
    "# === Normalize inputs and targets ===\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train = scaler_x.fit_transform(df[input_cols].values.astype(np.float32))\n",
    "Y_train = scaler_y.fit_transform(df[target_cols].values.astype(np.float32))\n",
    "\n",
    "# Save scalers\n",
    "with open(r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\scaler_x.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler_x, f)\n",
    "with open(r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\scaler_y.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler_y, f)\n",
    "\n",
    "# === Define Improved Autoencoder ===\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, bottleneck_dim=300, output_dim=None):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        output_dim = output_dim or input_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, bottleneck_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(bottleneck_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# === Training setup ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Autoencoder(input_dim=X_train.shape[1], output_dim=Y_train.shape[1]).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train).float(), torch.tensor(Y_train).float())\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# === Training loop ===\n",
    "epochs = 300\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    scheduler.step(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.6f}\")\n",
    "\n",
    "# === Save model ===\n",
    "save_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\autoencoder_model.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b99672c-9f99-4b35-b760-a6c87e9df426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geology_id</th>\n",
       "      <th>-299</th>\n",
       "      <th>-298</th>\n",
       "      <th>-297</th>\n",
       "      <th>-296</th>\n",
       "      <th>-295</th>\n",
       "      <th>-294</th>\n",
       "      <th>-293</th>\n",
       "      <th>-292</th>\n",
       "      <th>-291</th>\n",
       "      <th>...</th>\n",
       "      <th>-9</th>\n",
       "      <th>-8</th>\n",
       "      <th>-7</th>\n",
       "      <th>-6</th>\n",
       "      <th>-5</th>\n",
       "      <th>-4</th>\n",
       "      <th>-3</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g_4a52df537a</td>\n",
       "      <td>0.722889</td>\n",
       "      <td>0.722889</td>\n",
       "      <td>0.722889</td>\n",
       "      <td>0.722889</td>\n",
       "      <td>0.722889</td>\n",
       "      <td>0.722889</td>\n",
       "      <td>0.722889</td>\n",
       "      <td>0.722889</td>\n",
       "      <td>0.722889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066388</td>\n",
       "      <td>0.059011</td>\n",
       "      <td>0.051635</td>\n",
       "      <td>0.044258</td>\n",
       "      <td>0.036882</td>\n",
       "      <td>0.029506</td>\n",
       "      <td>0.022129</td>\n",
       "      <td>0.014753</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g_1e4b5a1509</td>\n",
       "      <td>-3.892460</td>\n",
       "      <td>-3.879441</td>\n",
       "      <td>-3.866423</td>\n",
       "      <td>-3.853405</td>\n",
       "      <td>-3.840387</td>\n",
       "      <td>-3.827368</td>\n",
       "      <td>-3.814350</td>\n",
       "      <td>-3.801332</td>\n",
       "      <td>-3.788313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117164</td>\n",
       "      <td>-0.104146</td>\n",
       "      <td>-0.091128</td>\n",
       "      <td>-0.078110</td>\n",
       "      <td>-0.065091</td>\n",
       "      <td>-0.052073</td>\n",
       "      <td>-0.039055</td>\n",
       "      <td>-0.026037</td>\n",
       "      <td>-0.013018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g_5919c0bea3</td>\n",
       "      <td>-6.989506</td>\n",
       "      <td>-6.989506</td>\n",
       "      <td>-6.989506</td>\n",
       "      <td>-6.989506</td>\n",
       "      <td>-6.989506</td>\n",
       "      <td>-6.989506</td>\n",
       "      <td>-6.989506</td>\n",
       "      <td>-6.989506</td>\n",
       "      <td>-6.989506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.241023</td>\n",
       "      <td>-0.214243</td>\n",
       "      <td>-0.187462</td>\n",
       "      <td>-0.160682</td>\n",
       "      <td>-0.133902</td>\n",
       "      <td>-0.107121</td>\n",
       "      <td>-0.080341</td>\n",
       "      <td>-0.053561</td>\n",
       "      <td>-0.026780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g_9a665aae6d</td>\n",
       "      <td>-7.536374</td>\n",
       "      <td>-7.536374</td>\n",
       "      <td>-7.536374</td>\n",
       "      <td>-7.536374</td>\n",
       "      <td>-7.536374</td>\n",
       "      <td>-7.536374</td>\n",
       "      <td>-7.536374</td>\n",
       "      <td>-7.536374</td>\n",
       "      <td>-7.536374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371052</td>\n",
       "      <td>-0.329824</td>\n",
       "      <td>-0.288596</td>\n",
       "      <td>-0.247368</td>\n",
       "      <td>-0.206140</td>\n",
       "      <td>-0.164912</td>\n",
       "      <td>-0.123684</td>\n",
       "      <td>-0.082456</td>\n",
       "      <td>-0.041228</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g_ba4abe1b9e</td>\n",
       "      <td>-2.061645</td>\n",
       "      <td>-2.061645</td>\n",
       "      <td>-2.061645</td>\n",
       "      <td>-2.061645</td>\n",
       "      <td>-2.061645</td>\n",
       "      <td>-2.061645</td>\n",
       "      <td>-2.061645</td>\n",
       "      <td>-2.061645</td>\n",
       "      <td>-2.061645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178712</td>\n",
       "      <td>-0.158855</td>\n",
       "      <td>-0.138998</td>\n",
       "      <td>-0.119141</td>\n",
       "      <td>-0.099284</td>\n",
       "      <td>-0.079427</td>\n",
       "      <td>-0.059571</td>\n",
       "      <td>-0.039714</td>\n",
       "      <td>-0.019857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     geology_id      -299      -298      -297      -296      -295      -294  \\\n",
       "0  g_4a52df537a  0.722889  0.722889  0.722889  0.722889  0.722889  0.722889   \n",
       "1  g_1e4b5a1509 -3.892460 -3.879441 -3.866423 -3.853405 -3.840387 -3.827368   \n",
       "2  g_5919c0bea3 -6.989506 -6.989506 -6.989506 -6.989506 -6.989506 -6.989506   \n",
       "3  g_9a665aae6d -7.536374 -7.536374 -7.536374 -7.536374 -7.536374 -7.536374   \n",
       "4  g_ba4abe1b9e -2.061645 -2.061645 -2.061645 -2.061645 -2.061645 -2.061645   \n",
       "\n",
       "       -293      -292      -291  ...        -9        -8        -7        -6  \\\n",
       "0  0.722889  0.722889  0.722889  ...  0.066388  0.059011  0.051635  0.044258   \n",
       "1 -3.814350 -3.801332 -3.788313  ... -0.117164 -0.104146 -0.091128 -0.078110   \n",
       "2 -6.989506 -6.989506 -6.989506  ... -0.241023 -0.214243 -0.187462 -0.160682   \n",
       "3 -7.536374 -7.536374 -7.536374  ... -0.371052 -0.329824 -0.288596 -0.247368   \n",
       "4 -2.061645 -2.061645 -2.061645  ... -0.178712 -0.158855 -0.138998 -0.119141   \n",
       "\n",
       "         -5        -4        -3        -2        -1    0  \n",
       "0  0.036882  0.029506  0.022129  0.014753  0.007376  0.0  \n",
       "1 -0.065091 -0.052073 -0.039055 -0.026037 -0.013018  0.0  \n",
       "2 -0.133902 -0.107121 -0.080341 -0.053561 -0.026780  0.0  \n",
       "3 -0.206140 -0.164912 -0.123684 -0.082456 -0.041228  0.0  \n",
       "4 -0.099284 -0.079427 -0.059571 -0.039714 -0.019857  0.0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the test dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\ML Database\\Geology Datasets\\data\\test.csv\")\n",
    "\n",
    "# Exclude the 'geology_id' column from interpolation\n",
    "columns_to_interpolate = df.columns[df.columns != 'geology_id']\n",
    "\n",
    "# Apply linear interpolation across columns (axis=1)\n",
    "df[columns_to_interpolate] = df[columns_to_interpolate].interpolate(\n",
    "    method='linear', axis=1, limit_direction='both'\n",
    ")\n",
    "\n",
    "# Fallback: Fill any remaining NaNs with column means\n",
    "df[columns_to_interpolate] = df[columns_to_interpolate].fillna(df[columns_to_interpolate].mean())\n",
    "\n",
    "# Define the path to save the new CSV\n",
    "save_folder = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder, \"filled_test.csv\")\n",
    "\n",
    "# Save the filled DataFrame\n",
    "df.to_csv(save_path, index=False)\n",
    "\n",
    "# Optionally print the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc12042-3aeb-45d3-8cd0-78674e82c16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to: C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "#ORGINAL, ACCURACY OF 66!\n",
    "# Define Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=1024, bottleneck_dim=300, output_dim=None):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        output_dim = output_dim or input_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, bottleneck_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(bottleneck_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Paths\n",
    "model_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\autoencoder_model.pth\"\n",
    "target_cols_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\target_cols.pkl\"\n",
    "test_filled_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\filled_test.csv\"\n",
    "submission_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\submission.csv\"\n",
    "\n",
    "# Load filled test data\n",
    "df_test = pd.read_csv(test_filled_path)\n",
    "\n",
    "# Extract geology_id separately\n",
    "geology_ids = df_test[\"geology_id\"].reset_index(drop=True)\n",
    "\n",
    "# Use only columns from -299 to 0 for input\n",
    "input_cols = [str(i) for i in range(-299, 1) if str(i) in df_test.columns]\n",
    "\n",
    "# Load target column names saved during training\n",
    "with open(target_cols_path, \"rb\") as f:\n",
    "    target_cols = pickle.load(f)\n",
    "\n",
    "input_dim = len(input_cols)\n",
    "output_dim = len(target_cols)\n",
    "\n",
    "# Load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Autoencoder(input_dim=input_dim, output_dim=output_dim)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Prepare input tensor\n",
    "X_test = df_test[input_cols].values.astype('float32')\n",
    "X_test_tensor = torch.tensor(X_test).to(device)\n",
    "\n",
    "# Reconstruct full features\n",
    "with torch.no_grad():\n",
    "    reconstructed = model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "# Create DataFrame with reconstructed columns\n",
    "df_reconstructed = pd.DataFrame(reconstructed, columns=target_cols)\n",
    "\n",
    "# Combine geology_id with predictions\n",
    "df_submission = pd.concat([geology_ids, df_reconstructed], axis=1)\n",
    "\n",
    "# Save to submission.csv\n",
    "df_submission.to_csv(submission_path, index=False)\n",
    "print(f\"Submission file saved to: {submission_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7a35eec-9513-4fd6-ad49-6f184debebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to: C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "\n",
    "# === Define Improved Autoencoder (matches training) ===\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, bottleneck_dim=300, output_dim=None):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        output_dim = output_dim or input_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, bottleneck_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(bottleneck_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# === Paths ===\n",
    "model_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\autoencoder_model.pth\"\n",
    "target_cols_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\target_cols.pkl\"\n",
    "scaler_x_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\scaler_x.pkl\"\n",
    "scaler_y_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\scaler_y.pkl\"\n",
    "test_filled_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\filled_test.csv\"\n",
    "submission_path = r\"C:\\Users\\Nokul\\Desktop\\Codes\\Python Codes\\Machine Learning\\Geology ML Project\\submission.csv\"\n",
    "\n",
    "# === Load test data ===\n",
    "df_test = pd.read_csv(test_filled_path)\n",
    "geology_ids = df_test[\"geology_id\"].reset_index(drop=True)\n",
    "input_cols = [str(i) for i in range(-299, 1) if str(i) in df_test.columns]\n",
    "\n",
    "# === Load saved column list and scalers ===\n",
    "with open(target_cols_path, \"rb\") as f:\n",
    "    target_cols = pickle.load(f)\n",
    "\n",
    "with open(scaler_x_path, \"rb\") as f:\n",
    "    scaler_x = pickle.load(f)\n",
    "\n",
    "with open(scaler_y_path, \"rb\") as f:\n",
    "    scaler_y = pickle.load(f)\n",
    "\n",
    "# === Normalize input using same scaler from training ===\n",
    "X_test = df_test[input_cols].values.astype('float32')\n",
    "X_test_scaled = scaler_x.transform(X_test)\n",
    "\n",
    "# === Model setup ===\n",
    "input_dim = len(input_cols)\n",
    "output_dim = len(target_cols)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Autoencoder(input_dim=input_dim, output_dim=output_dim).to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# === Predict reconstructed output ===\n",
    "X_test_tensor = torch.tensor(X_test_scaled).to(device)\n",
    "with torch.no_grad():\n",
    "    reconstructed = model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "# === Inverse transform predictions to original scale ===\n",
    "reconstructed_original = scaler_y.inverse_transform(reconstructed)\n",
    "\n",
    "# === Create submission dataframe ===\n",
    "df_reconstructed = pd.DataFrame(reconstructed_original, columns=target_cols)\n",
    "df_submission = pd.concat([geology_ids, df_reconstructed], axis=1)\n",
    "\n",
    "# === Save submission ===\n",
    "df_submission.to_csv(submission_path, index=False)\n",
    "print(f\"Submission file saved to: {submission_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
